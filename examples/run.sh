# CUDA_VISIBLE_DEVICES=0,1,2 nohup python -m torch.distributed.launch --nproc_per_node=3 wandb_gpt4kt_train.py --d_ff=1024 --d_model=1024 --dataset_name=pretrain --dropout=0.05 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 > gpt4kt.txt &
# CUDA_VISIBLE_DEVICES=0,1,2 nohup python -m torch.distributed.launch --nproc_per_node=3 wandb_gpt4kt_train.py --d_ff=1024 --d_model=1024 --dataset_name=pretrain --dropout=0.3 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 > gpt4kt1.txt &
# CUDA_VISIBLE_DEVICES=5,6,7 nohup python -m torch.distributed.launch --nproc_per_node=3 wandb_gpt4kt_train.py --d_ff=1024 --d_model=1024 --dataset_name=pretrain --dropout=0.5 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 > gpt4kt2.txt &
# CUDA_VISIBLE_DEVICES=5,6,7 nohup python -m torch.distributed.launch --nproc_per_node=3 wandb_gpt4kt_train.py --d_ff=1024 --d_model=1024 --dataset_name=pretrain --dropout=0.05 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.0001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 > gpt4kt3.txt &
# CUDA_VISIBLE_DEVICES=5,6,7 nohup python -m torch.distributed.launch --nproc_per_node=3 wandb_gpt4kt_train.py --d_ff=1024 --d_model=1024 --dataset_name=pretrain --dropout=0.05 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.00001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 > gpt4kt4.txt &



# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 nohup python -m torch.distributed.launch --nproc_per_node=8 wandb_gpt4kt_train.py --d_ff=1024 --d_model=1024 --dataset_name=pretrain --dropout=0.05 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=1024 > gpt4kt1024_1.txt &
# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 nohup python -m torch.distributed.launch --nproc_per_node=8 wandb_gpt4kt_train.py --d_ff=1024 --d_model=1024 --dataset_name=pretrain --dropout=0.3 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=1024 > gpt4kt1024_2.txt &
# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 nohup python -m torch.distributed.launch --nproc_per_node=8 wandb_gpt4kt_train.py --d_ff=1024 --d_model=1024 --dataset_name=pretrain --dropout=0.5 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=1024 > gpt4kt1024_3.txt &
# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 WANDB_API_KEY=07ec58f8e8315aa083a202292092d7e2ee9d43b4 nohup python -m torch.distributed.launch --nproc_per_node=8 wandb_gpt4kt_train.py --d_ff=1024 --d_model=1024 --dataset_name=pretrain --dropout=0.05 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.0001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=1024 > gpt4kt1024_4.txt &
# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 WANDB_API_KEY=07ec58f8e8315aa083a202292092d7e2ee9d43b4 nohup python -m torch.distributed.launch --nproc_per_node=8 wandb_gpt4kt_train.py --d_ff=1024 --d_model=1024 --dataset_name=pretrain --dropout=0.1 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=1024 > gpt4kt1024_6.txt &

# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 WANDB_API_KEY=07ec58f8e8315aa083a202292092d7e2ee9d43b4 nohup python -m torch.distributed.launch --nproc_per_node=8 wandb_gpt4kt_train.py --d_ff=1024 --d_model=1024 --dataset_name=pretrain --dropout=0.3 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.0001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=1024 > gpt4kt1024_6.txt &



# new hyparameter-tunning

#  middle
# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 WANDB_API_KEY=07ec58f8e8315aa083a202292092d7e2ee9d43b4 nohup python -m torch.distributed.launch --nproc_per_node=8 wandb_gpt4kt_train.py --d_ff=1024 --d_model=1024 --dataset_name=pretrain --dropout=0.1 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=200 > gpt4kt_mid200_1.txt &
# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 WANDB_API_KEY=07ec58f8e8315aa083a202292092d7e2ee9d43b4 nohup python -m torch.distributed.launch --nproc_per_node=8 wandb_gpt4kt_train.py --d_ff=1024 --d_model=1024 --dataset_name=pretrain --dropout=0.1 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.0001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=200 > gpt4kt_mid200_2.txt &
# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 WANDB_API_KEY=07ec58f8e8315aa083a202292092d7e2ee9d43b4 nohup python -m torch.distributed.launch --nproc_per_node=8 wandb_gpt4kt_train.py --d_ff=1024 --d_model=1024 --dataset_name=pretrain --dropout=0.1 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=1024 > gpt4kt_mid1024_1.txt &
# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 WANDB_API_KEY=07ec58f8e8315aa083a202292092d7e2ee9d43b4 nohup python -m torch.distributed.launch --nproc_per_node=8 wandb_gpt4kt_train.py --d_ff=1024 --d_model=1024 --dataset_name=pretrain --dropout=0.1 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.0001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=1024 > gpt4kt_mid1024_2.txt &

# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 WANDB_API_KEY=07ec58f8e8315aa083a202292092d7e2ee9d43b4 nohup python -m torch.distributed.launch --nproc_per_node=8 wandb_gpt4kt_train.py --d_ff=1024 --d_model=1024 --dataset_name=pretrain --dropout=0.1 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=512 > gpt4kt_mid512_1.txt &
# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 WANDB_API_KEY=07ec58f8e8315aa083a202292092d7e2ee9d43b4 nohup python -m torch.distributed.launch --nproc_per_node=8 wandb_gpt4kt_train.py --d_ff=1024 --d_model=1024 --dataset_name=pretrain --dropout=0.1 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.0001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=512 > gpt4kt_mid512_2.txt &


# mini-middel
# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 WANDB_API_KEY=07ec58f8e8315aa083a202292092d7e2ee9d43b4 nohup python -m torch.distributed.launch --nproc_per_node=8 wandb_gpt4kt_train.py --d_ff=1024 --d_model=512 --dataset_name=pretrain --dropout=0.1 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=200 > gpt4kt_mid200_1.txt &
# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 WANDB_API_KEY=07ec58f8e8315aa083a202292092d7e2ee9d43b4 nohup python -m torch.distributed.launch --nproc_per_node=8 wandb_gpt4kt_train.py --d_ff=1024 --d_model=512 --dataset_name=pretrain --dropout=0.1 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.0001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=200 > gpt4kt_mid200_2.txt &
# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 WANDB_API_KEY=07ec58f8e8315aa083a202292092d7e2ee9d43b4 nohup python -m torch.distributed.launch --nproc_per_node=8 wandb_gpt4kt_train.py --d_ff=1024 --d_model=512 --dataset_name=pretrain --dropout=0.1 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=1024 > gpt4kt_mid1024_1.txt &
# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 WANDB_API_KEY=07ec58f8e8315aa083a202292092d7e2ee9d43b4 nohup python -m torch.distributed.launch --nproc_per_node=8 wandb_gpt4kt_train.py --d_ff=1024 --d_model=512 --dataset_name=pretrain --dropout=0.1 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.0001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=1024 > gpt4kt_mid1024_2.txt &
# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 WANDB_API_KEY=07ec58f8e8315aa083a202292092d7e2ee9d43b4 nohup python -m torch.distributed.launch --nproc_per_node=8 wandb_gpt4kt_train.py --d_ff=1024 --d_model=512 --dataset_name=pretrain --dropout=0.1 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=512 > gpt4kt_mid512_1.txt &
# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 WANDB_API_KEY=07ec58f8e8315aa083a202292092d7e2ee9d43b4 nohup python -m torch.distributed.launch --nproc_per_node=8 wandb_gpt4kt_train.py --d_ff=1024 --d_model=512 --dataset_name=pretrain --dropout=0.1 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.0001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=512 > gpt4kt_mid512_2.txt &


# 1B model
# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 WANDB_API_KEY=07ec58f8e8315aa083a202292092d7e2ee9d43b4 nohup python -m torch.distributed.launch --nproc_per_node=8 wandb_gpt4kt_train.py --d_ff=2560 --d_model=1536 --dataset_name=pretrain --dropout=0.1 --emb_type=qid --final_fc_dim=1536 --final_fc_dim2=1024 --fold=0 --learning_rate=0.001 --model_name=gpt4kt --n_blocks=32 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=200 > gpt4kt_mid512_1.txt &

# split training data 
# CUDA_VISIBLE_DEVICES=3 WANDB_API_KEY=07ec58f8e8315aa083a202292092d7e2ee9d43b4 nohup python -m torch.distributed.launch --nproc_per_node=1 --master_port=12340 wandb_gpt4kt_train.py --d_ff=1024 --d_model=512 --dataset_name=pretrain --dropout=0.1 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.0001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=200 --train_ratio=0.9 --num_gpus=1  > gpt4kt_mid200_0.9.txt &
# CUDA_VISIBLE_DEVICES=0 WANDB_API_KEY=07ec58f8e8315aa083a202292092d7e2ee9d43b4 nohup python -m torch.distributed.launch --nproc_per_node=1 --master_port=12345 wandb_gpt4kt_train.py --d_ff=1024 --d_model=512 --dataset_name=pretrain --dropout=0.1 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.0001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=200 --train_ratio=0.8 --num_gpus=1  > gpt4kt_mid200_0.8.txt &
# CUDA_VISIBLE_DEVICES=1 WANDB_API_KEY=07ec58f8e8315aa083a202292092d7e2ee9d43b4 nohup python -m torch.distributed.launch --nproc_per_node=1 --master_port=12344 wandb_gpt4kt_train.py --d_ff=1024 --d_model=512 --dataset_name=pretrain --dropout=0.1 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.0001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=200 --train_ratio=0.7 --num_gpus=1 > gpt4kt_mid200_0.7.txt &
# # CUDA_VISIBLE_DEVICES=2 WANDB_API_KEY=07ec58f8e8315aa083a202292092d7e2ee9d43b4 nohup python -m torch.distributed.launch --nproc_per_node=1 --master_port=12345 wandb_gpt4kt_train.py --d_ff=1024 --d_model=512 --dataset_name=pretrain --dropout=0.1 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.0001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=200 --train_ratio=0.6 --num_gpus=1 > gpt4kt_mid200_0.6.txt &
# CUDA_VISIBLE_DEVICES=3 WANDB_API_KEY=07ec58f8e8315aa083a202292092d7e2ee9d43b4 nohup python -m torch.distributed.launch --nproc_per_node=1 --master_port=12346 wandb_gpt4kt_train.py --d_ff=1024 --d_model=512 --dataset_name=pretrain --dropout=0.1 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.0001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=200 --train_ratio=0.5 --num_gpus=1 > gpt4kt_mid200_0.5.txt &
# CUDA_VISIBLE_DEVICES=4 WANDB_API_KEY=07ec58f8e8315aa083a202292092d7e2ee9d43b4 nohup python -m torch.distributed.launch --nproc_per_node=1 --master_port=12347 wandb_gpt4kt_train.py --d_ff=1024 --d_model=512 --dataset_name=pretrain --dropout=0.1 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.0001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=200 --train_ratio=0.4 --num_gpus=1 > gpt4kt_mid200_0.4.txt &
# CUDA_VISIBLE_DEVICES=5 WANDB_API_KEY=07ec58f8e8315aa083a202292092d7e2ee9d43b4 nohup python -m torch.distributed.launch --nproc_per_node=1 --master_port=12348 wandb_gpt4kt_train.py --d_ff=1024 --d_model=512 --dataset_name=pretrain --dropout=0.1 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.0001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=200 --train_ratio=0.3 --num_gpus=1 > gpt4kt_mid200_0.3.txt &
# CUDA_VISIBLE_DEVICES=6 WANDB_API_KEY=07ec58f8e8315aa083a202292092d7e2ee9d43b4 nohup python -m torch.distributed.launch --nproc_per_node=1 --master_port=12349 wandb_gpt4kt_train.py --d_ff=1024 --d_model=512 --dataset_name=pretrain --dropout=0.1 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.0001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=200 --train_ratio=0.2 --num_gpus=1 > gpt4kt_mid200_0.2.txt &
# CUDA_VISIBLE_DEVICES=7 WANDB_API_KEY=07ec58f8e8315aa083a202292092d7e2ee9d43b4 nohup python -m torch.distributed.launch --nproc_per_node=1 --master_port=12350 wandb_gpt4kt_train.py --d_ff=1024 --d_model=512 --dataset_name=pretrain --dropout=0.1 --emb_type=qid --final_fc_dim=512 --final_fc_dim2=1024 --fold=0 --learning_rate=0.0001 --model_name=gpt4kt --n_blocks=24 --num_attn_heads=16 --save_dir=models/gpt4kt_tiaocan_pretrain --seed=3407 --seq_len=200 --train_ratio=0.1 --num_gpus=1 > gpt4kt_mid200_0.1.txt &