{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONE_KEYS = [\"fold\", \"uid\", \"dataset\"]\n",
    "ALL_KEYS = [\n",
    "    \"fold\",\n",
    "    \"uid\",\n",
    "    \"questions\",\n",
    "    \"concepts\",\n",
    "    \"responses\",\n",
    "    \"timestamps\",\n",
    "    \"usetimes\",\n",
    "    \"selectmasks\",\n",
    "    \"is_repeat\",\n",
    "    \"qidxs\",\n",
    "    \"rest\",\n",
    "    \"orirow\",\n",
    "    \"cidxs\",\n",
    "    \"dataset\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calStatistics(df, stares, key):\n",
    "    allin, allselect = 0, 0\n",
    "    allqs, allcs = set(), set()\n",
    "    for i, row in df.iterrows():\n",
    "        rs = row[\"responses\"].split(\",\")\n",
    "        curlen = len(rs) - rs.count(\"-1\")\n",
    "        allin += curlen\n",
    "        if \"selectmasks\" in row:\n",
    "            ss = row[\"selectmasks\"].split(\",\")\n",
    "            slen = ss.count(\"1\")\n",
    "            allselect += slen\n",
    "        if \"concepts\" in row:\n",
    "            cs = row[\"concepts\"].split(\",\")\n",
    "            fc = list()\n",
    "            for c in cs:\n",
    "                cc = c.split(\"_\")\n",
    "                fc.extend(cc)\n",
    "            curcs = set(fc) - {\"-1\"}\n",
    "            allcs |= curcs\n",
    "        if \"questions\" in row:\n",
    "            qs = row[\"questions\"].split(\",\")\n",
    "            curqs = set(qs) - {\"-1\"}\n",
    "            allqs |= curqs\n",
    "    stares.append(\",\".join([str(s) for s in [key, allin, df.shape[0], allselect]]))\n",
    "    return allin, allselect, len(allqs), len(allcs), df.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dcur(row, effective_keys):\n",
    "    dcur = dict()\n",
    "    for key in effective_keys:\n",
    "        if key not in ONE_KEYS:\n",
    "            dcur[key] = row[key].split(\",\")  # [int(i) for i in row[key].split(\",\")]\n",
    "        else:\n",
    "            dcur[key] = row[key]\n",
    "    return dcur\n",
    "\n",
    "\n",
    "def generate_sequences(df, effective_keys, min_seq_len=3, maxlen=200, pad_val=-1):\n",
    "    # 判断df中是否有timestamps列，如果有，则effective_keys中加入timestamps\n",
    "    if \"timestamps\" in df.columns:\n",
    "        effective_keys.add(\"timestamps\")\n",
    "    save_keys = list(effective_keys) + [\"selectmasks\"]\n",
    "    dres = {\"selectmasks\": []}\n",
    "    dropnum = 0\n",
    "    for i, row in df.iterrows():\n",
    "        dcur = save_dcur(row, effective_keys)\n",
    "\n",
    "        rest, lenrs = len(dcur[\"responses\"]), len(dcur[\"responses\"])\n",
    "        j = 0\n",
    "        while lenrs >= j + maxlen:\n",
    "            rest = rest - (maxlen)\n",
    "            for key in effective_keys:\n",
    "                dres.setdefault(key, [])\n",
    "                if key not in ONE_KEYS:\n",
    "                    dres[key].append(\n",
    "                        \",\".join(dcur[key][j : j + maxlen])\n",
    "                    )  # [str(k) for k in dcur[key][j: j + maxlen]]))\n",
    "                else:\n",
    "                    dres[key].append(dcur[key])\n",
    "            dres[\"selectmasks\"].append(\",\".join([\"1\"] * maxlen))\n",
    "\n",
    "            j += maxlen\n",
    "        if rest < min_seq_len:  # delete sequence len less than min_seq_len\n",
    "            dropnum += rest\n",
    "            continue\n",
    "\n",
    "        pad_dim = maxlen - rest\n",
    "        for key in effective_keys:\n",
    "            dres.setdefault(key, [])\n",
    "            if key not in ONE_KEYS:\n",
    "                paded_info = np.concatenate(\n",
    "                    [dcur[key][j:], np.array([pad_val] * pad_dim)]\n",
    "                )\n",
    "                dres[key].append(\",\".join([str(k) for k in paded_info]))\n",
    "            else:\n",
    "                dres[key].append(dcur[key])\n",
    "        dres[\"selectmasks\"].append(\",\".join([\"1\"] * rest + [str(pad_val)] * pad_dim))\n",
    "\n",
    "    # after preprocess data, report\n",
    "    dfinal = dict()\n",
    "    for key in ALL_KEYS:\n",
    "        if key in save_keys:\n",
    "            dfinal[key] = dres[key]\n",
    "    finaldf = pd.DataFrame(dfinal)\n",
    "    print(f\"dropnum: {dropnum}\")\n",
    "    return finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sub_data(df, train_ratio):\n",
    "    final_sub_df = pd.DataFrame()\n",
    "    \n",
    "    # 对每个fold 按比例抽取\n",
    "    for fold in range(5):\n",
    "        sub_df = df[df[\"fold\"] == fold]\n",
    "        sub_df = sub_df.sample(frac=train_ratio,random_state=1024)\n",
    "        final_sub_df = pd.concat([final_sub_df, sub_df],ignore_index=True)\n",
    "    print(\n",
    "        f\"extract_sub_origin_data...original_stu_nums:{df.shape}, extract_nums:{final_sub_df.shape}\"\n",
    "    )\n",
    "    return final_sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_dataset(data_config, train_ratio=1.0):\n",
    "    df = pd.read_csv(\n",
    "        os.path.join(data_config[\"dpath\"], f\"train_valid_quelevel.csv\")\n",
    "        )\n",
    "    ins, ss, qs, cs, seqnum = calStatistics(\n",
    "        df=df, stares=[], key=\"original train+valid question level\"\n",
    "    )\n",
    "    print(\n",
    "        f\"origin interactions num: {ins}, select num: {ss}, qs: {qs}, cs: {cs}, seqnum: {seqnum}\"\n",
    "    )\n",
    "    if train_ratio < 1.0:\n",
    "        sub_data_path = os.path.join(\n",
    "            data_config[\"dpath\"], f\"train_valid_quelevel_{train_ratio}.csv\"\n",
    "        )\n",
    "        if not os.path.exists(sub_data_path):\n",
    "            finaldf = extract_sub_data(df, train_ratio)\n",
    "            # finaldf.to_csv(sub_data_path)\n",
    "        else:\n",
    "            finaldf = pd.read_csv(sub_data_path)\n",
    "        ins, ss, qs, cs, seqnum = calStatistics(\n",
    "            df=finaldf, stares=[], key=\"original train+valid question level\"\n",
    "        )   \n",
    "        print(\n",
    "            f\"after extract interactions num: {ins}, select num: {ss}, qs: {qs}, cs: {cs}, seqnum: {seqnum}\"\n",
    "        )\n",
    "    sub_sequence_df = generate_sequences(\n",
    "        finaldf,\n",
    "        effective_keys={\n",
    "            \"uid\",\n",
    "            \"questions\",\n",
    "            \"concepts\",\n",
    "            \"responses\",\n",
    "            \"fold\"\n",
    "        },\n",
    "        min_seq_len=3,\n",
    "        maxlen=200,\n",
    "        pad_val=-1\n",
    "    )\n",
    "    # debug，暂时不保存为csv文件\n",
    "    # dpath = data_config[\"dpath\"]\n",
    "    # if train_ratio < 1.0:\n",
    "    #     sub_sequence_df.to_csv(\n",
    "    #         f\"{dpath}/train_valid_sequences_quelevel_{train_ratio}.csv\",\n",
    "    #         index=None\n",
    "    #     )\n",
    "    # else:\n",
    "    #     print(\"do not have ratio\")\n",
    "    \n",
    "    ins, ss, qs, cs, seqnum = calStatistics(\n",
    "        df=sub_sequence_df, stares=[], key=\"train+valid sequences question level\"\n",
    "    )\n",
    "    print(\n",
    "        f\"after extract  sequences interactions num: {ins}, select num: {ss}, qs: {qs}, cs: {cs}, seqnum: {seqnum}\"\n",
    "    )\n",
    "    \n",
    "    return sub_sequence_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin interactions num: 4446825, select num: 0, qs: 7619, cs: 865, seqnum: 14453\n",
      "after extract interactions num: 1329154, select num: 0, qs: 7340, cs: 855, seqnum: 4335\n",
      "dropnum: 147\n",
      "after extract  sequences interactions num: 1329007, select num: 1329007, qs: 7339, cs: 855, seqnum: 9261\n"
     ]
    }
   ],
   "source": [
    "with open(\"../../configs/data_config.json\", \"r\") as f:\n",
    "    data_config = json.load(f)\n",
    "data_config = data_config[\"peiyou\"]\n",
    "sub_df = get_split_dataset(data_config,train_ratio=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30965, 7)\n",
      "(9261, 7)\n"
     ]
    }
   ],
   "source": [
    "origin = pd.read_csv(os.path.join(data_config[\"dpath\"], \"train_valid_sequences_quelevel.csv\"))\n",
    "print(origin.shape)\n",
    "print(sub_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zion_unikt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
